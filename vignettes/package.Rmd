---
title: "package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{package}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(hardhat)
```

TODO - Finish me

## High level ideas here

- Introduce a modeling function that you might use in a package

- Demonstrate the constructor

- Demonstrate an implementation function

- Demonstrate the user facing interface

- Show how to call `mold()` in this setup to preprocess data

- And show how the engine gets added to the constructor

- Then create a `predict()` method

- Create a predict impl

- Add in `forge()` to the predict method

## Introduction

The goal of this vignette is to teach you how to use `mold()` and `forge()` in a modeling package. This is the intended use of these functions, even though they can also be called interactively. Creating a new modeling package has two main stages, creating the modeling function, and implementing a predict method. The stages break down like this:

- Modeling function
  
  - Create a constructor
  
  - Create an implementation function
  
  - Create a user facing function with methods for xy, formula, and recipe interfaces
  
- Predict method

  - Create one or more predict implementation function, varying by the `"type"` of prediction to make
  
  - Create a user facing predict method

## What's Our Model?

We will use the underlying `lm()` infrastructure, `lm.fit()`, to create our model. Linear regression should be recognizable to many, so we can focus on understanding how `mold()` and `forge()` fit in the picture, rather than understanding how the model works.

`lm.fit()` takes `x` and `y` directly, rather than using the formula method. It will serve as the core part of our modeling implementation function, and generally it is easiest if the implementation function takes `x` and `y` in this manner.

## Model Constructor

The first thing we need is a _constructor_ that creates new objects of our model class. The hardhat function `new_base_model()` can help with creating that. Our constructor should have the name `new_<class>()`, should take all of the required pieces to the model as named arguments, and should pass them on to `new_base_model()` which will return a classed list.

```{r}
new_linear_regression <- function(coefs, coef_names, engine) {
  
  if (!is.numeric(coefs)) {
    stop("`coefs` should be a numeric vector.", call. = FALSE)
  }
  
  if (!is.character(coef_names)) {
    stop("`coef_names` should be a character vector.", call. = FALSE)
  }
  
  if (length(coefs) != length(coef_names)) {
    stop("`coefs` and `coef_names` must have the same length.")
  }
  
  new_model(
    coefs = coefs, 
    coef_names = coef_names,
    engine = engine, 
    class = "linear_regression"
  )
}
```

```{r}
linear_regression_impl <- function(predictors, outcomes) {
  lm_fit <- lm.fit(predictors, outcomes)
  
  coefs <- lm_fit$coefficients
  
  coef_names <- names(coefs)
  coefs <- unname(coefs)
  
  list(
    coefs = coefs,
    coef_names = coef_names
  )
}
```

```{r}
linear_regression_wrapper <- function(processed) {
  
  x <- as.matrix(processed$predictors)
  y <- processed$outcomes[[1]]
  
  fit <- linear_regression_impl(x, y)
  
  new_linear_regression(
    coefs = fit$coefs,
    coef_names = fit$coef_names,
    engine = processed$engine
  )
}
```

```{r}
linear_regression <- function(x, ...) {
  UseMethod("linear_regression")
}

linear_regression.data.frame <- function(x, y, ...) {
  processed <- mold(x, y)
  linear_regression_wrapper(processed)
}

linear_regression.matrix <- function(x, y, ...) {
  processed <- mold(x, y)
  linear_regression_wrapper(processed)
}

linear_regression.formula <- function(formula, data, ...) {
  processed <- mold(formula, data)
  linear_regression_wrapper(processed)
}

linear_regression.recipe <- function(x, data, ...) {
  processed <- mold(x, data)
  linear_regression_wrapper(processed)
}
```


```{r}
linear_regression(iris[, "Sepal.Width", drop = FALSE], iris$Sepal.Length)
```


## `mold()` By Example

The intended use of `mold()` is to be called from your top level modeling function (the one that users will call). Suppose that we have such a function, `modeler()`, along with it's core implementation `modeler_impl()`, and a constructor to make a new `"modeler"` object, `new_modeler()`.

```{r}
# Create a new `modeler` object
new_modeler <- function(y_mean) {
  
  if (!is.numeric(y_mean)) {
    stop("`y_mean` must be numeric.")
  }
  
  elements <- list(
    y_mean = y_mean
  )
  
  structure(elements, class = "modeler")
}

# Implementation function
modeler_impl <- function(x, y) {
  
  # core modeling implementation
  
  list(
    y_mean = mean(y)
  )
}


modeler <- function(x, y) {
  res <- modeler_impl(x, y)
  new_modeler(y_mean = res$y_mean)
}
```

You probably expect users to use `modeler()` like this:

```{r}
# X and Y
x <- iris
x$Petal.Width <- NULL
y <- iris$Petal.Width

modeler(x, y)
```

When it comes time to make predictions, the first thing that you should do inside your `predict()` method is pass the user supplied data to `forge()`, along with the `engine` that was attached to the model object. This will preprocess the `new_data` using the same steps specified when the model was being trained.
